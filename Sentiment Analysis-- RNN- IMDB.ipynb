{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.4077 - acc: 0.8167 - val_loss: 0.4262 - val_acc: 0.8424\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.2372 - acc: 0.9100 - val_loss: 0.3179 - val_acc: 0.8664\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.1812 - acc: 0.9337 - val_loss: 0.2777 - val_acc: 0.8902\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 0.1542 - acc: 0.9439 - val_loss: 0.3116 - val_acc: 0.8840\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.1266 - acc: 0.9546 - val_loss: 0.2931 - val_acc: 0.8808\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.1115 - acc: 0.9617 - val_loss: 0.3675 - val_acc: 0.8744\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0964 - acc: 0.9690 - val_loss: 0.3424 - val_acc: 0.8792\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0835 - acc: 0.9719 - val_loss: 0.3615 - val_acc: 0.8778\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0743 - acc: 0.9749 - val_loss: 0.4158 - val_acc: 0.8840\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0684 - acc: 0.9784 - val_loss: 0.3919 - val_acc: 0.8794\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0590 - acc: 0.9813 - val_loss: 0.4484 - val_acc: 0.8692\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0516 - acc: 0.9840 - val_loss: 0.3668 - val_acc: 0.8804\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0461 - acc: 0.9864 - val_loss: 0.5140 - val_acc: 0.8738\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.0433 - acc: 0.9873 - val_loss: 0.5401 - val_acc: 0.8618\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.4485 - val_acc: 0.8758\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 43s 70ms/step - loss: 0.0323 - acc: 0.9906 - val_loss: 0.4180 - val_acc: 0.8778\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0291 - acc: 0.9911 - val_loss: 0.4885 - val_acc: 0.8770\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.6439 - val_acc: 0.8720\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.5160 - val_acc: 0.8764\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.5943 - val_acc: 0.8726\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.7172 - acc: 0.8423\n",
      "[0.7171850204467773, 0.8423200249671936]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 21  3 49 17  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.45543936], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n",
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=20, validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "\n",
    "# predict(rev)\n",
    "\n",
    "# #def review(rev):\n",
    "#     res=\"\"\n",
    "#     if predict(rev) > 0.5:\n",
    "#         res=\"Positive Review\"\n",
    "#     else:\n",
    "#         res=\"Negative Review\"\n",
    "#     return res\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12697896], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict(text):\n",
    "    encoded_text=encode_text(text)\n",
    "    pred= np.zeros((1,250))\n",
    "    pred[0]=encoded_text\n",
    "    result=model.predict(pred)\n",
    "#     print(result[0])\n",
    "    return result[0]\n",
    "\n",
    "rev = \"We'd not like to watch the movie again\"\n",
    "\n",
    "predict(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
